![](Logo_LabPUCP.png)

<center> <h1>Herramientas de la Ciencia de Datos <br></br>para la Investigación Social Reproducible</h1> </center>

<br></br>

* Profesor:  <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel Magallanes, PhD</a> ([jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe))<br>Profesor del **Departamento de Ciencias Sociales, Pontificia Universidad Católica del Peru**.<br>
Senior Data Scientist del **eScience Institute** and Visiting Professor at **Evans School of Public Policy and Governance, University of Washington**.<br>
Fellow Catalyst, **Berkeley Initiative for Transparency in Social Sciences, UC Berkeley**.

## Modelo de Integración

<br></br>

Este curso plantea apoyarte brindando diversas herramientas de la ciencia de datos a utilizar durante el proceso de investigación. Cada herramienta tiene una función determinada, sin embargo, a lo largo del taller, veremos cómo podemos integrarlas de una manera sencilla.

Para ello, les planteamos que podríamos abstraer el proceso de investigación según lo describe la Figura 1.

![](modelo.png)



Los elementos de la Figura 1 se dividen en dos grupos. En la parte superior figuran los grandes componentes:

* Definición del problema de investigación.
* Revisión de la literatura.
* Diseño del plan de investigación.
* Prueba de hipótesis.
* Publicación de resultados.

No he puesto una secuencia entre estos componentes, pues es evidente que hay una serie de idas y venidas entre estos. En todo caso no es mi intención discutir el orden de éstos, sino más bien ver qué herramientas podemos utilizar para  automatizar las diversas tareas relacionadas con cada una de ellas. Nótese que a cada componente se le ha asignado un color, y ese mismo color tienen las tareas ahí explicitadas; sin embargo, el hecho de no asignarle tareas al componente de definición de problema de investigación es por que este curso considera que ya sabes qué problema de investigación tienes. 

Así, he designado como automatizables diversas tareas. Y esto lo he decidido pues detrás de cada una hay alguna herramienta computacional que nos puede apoyar:

* Registrar referencias en una base de datos. Esto debe ser de tal manera que permita guardar los meta datos de diversos tipos de *documentos*: libros, revistas, vídeos, etc. 

* Incluir referencias en el documento. Poder hacer referencia cruzada entre la cita y la referencia; así como tener la flexibilidad de mostrar diversos sistemas de referencia (APA, Chicago, IEEE, Vancouver, etc.)

* Conseguir los datos mediante procesos diversos (experimentales y no experimentales), incluyendo procesos de *scrapeado*. Tener en cuenta que los datos inicialmente conseguidos pueden variar, o que con el avance de la investigación suceda que se encuentran mejores proxies.

* Preparar los datos, dándole el formato adecuado para que la técnica prevista sea aplicada. Ello varía si se piensa en modelos transversales, longitudinales, jerárquicos, redes, texto, mapas, entre otros. Esto amerita además procesos de integración de tablas de datos, así como la verificación que los datos sean consistentes con la escala de medida que representan.

* Organizar el archivo, es decir, decidir dónde se guardará los datos, tanto los originales como los procesados; y cómo se accederá a ellos, tanto los colaboradores como quiénes deseen auditar.

* Probar modelos con los datos según la hipótesis planteada, considerando que por diversas razones puedes intentar modelos alternativos (como decidir entre paramétrico y no paramétrico); hasta inclusive la hipótesis puede ser modificada por lo que esta tarea no es necesariamente la planificada. Los modelos son sensibles a los datos, y los datos pueden estar siendo actualizados constantemente.

* Actualizar estadísticos. Si los modelos y la data varían, los estadísticos varían; debemos tener maneras de que ello impacte lo menos posible en el documento en elaboración.

* Actualizar tablas. Igual que en el caso anterior, si los datos y los modelos varían, las tablas producidas inicialmente variarán; hay que evitar que el tiempo de re edición se reduzca.

* Actualizar gráficos. Este es el mismo caso que lo anteriormente mencionado, si los datos y los modelos varían, los gráficos producidas inicialmente variarán; y si son más complejos el costo de re edición aumenta (anotaciones, guías, títulos, paletas, etc.). La herramienta a utilizar debe tener en cuenta esta complejidad.

* Brindar interfaz visual. Por lo general, se tiene la necesidad de visualizar los avances. Muchas veces el asesor o el jefe del proyecto de investigación (o el corrector de estilo) quiere ver parte del trabajo . Esta persona no tiene que saber manejar las herramientas que verán Uds en el curso, sólo quiere ver cómo va el trabajo y preparar correcciones. Una interfaz es necesaria para ello.

* Producir documento. Aquí me refiero al documento final. Por lo general es un único documento pero también puede ser una colección de documentos integrados en uno solo. Hay que tener en cuenta que el *parcial*, que será el *final* es el que se irá visualizando en el interfaz, hasta que te decidas detener y poner el punto final.

Como también se muestra en la Figura 1, estas tareas están interrelacionadas, no se hacen de manera secuencial. Podríamos pensar en diversas relaciones entre ellas, siendo la más compleja la que hay entre el documento final y todas las demás.

Considera además que tantas idas y venidas durante el proceso de investigación nos acercan a cometer diversos errores de fondo y forma, que podrían ser controlados si hacemos uso de herramientas computacionales creadas para ayudar en diversas tareas, asi veremos:

- **Zotero**, para el manejo de las citas. Lo que necesitamos de Zotero es que pueda colectar la metadata de nuestras citas, nos permita editarla si lo necesitamos, y que permita su descarga como un archivo de citas que pueda ser usado en el documento integral. Para usar Zotero, debes crear una cuenta [aquí](https://www.zotero.org/), desde ahí debes descargar el *cliente* para tu computadora.

- **GitHub**, para organizar todos los archivos. GitHub guardará en la nube todo el trabajo, incluyendo datos, códigos, imagenes, citas, documento integrador, y similares. Para usar GitHub, debes crear una cuenta [aquí](https://github.com/), luego descarga el *cliente* para tu computadora en este [enlace](https://desktop.github.com/).

- **R**, En este curso desarrollaremos diversas técnicas en R. Descarga R desde este [enlace](https://cran.r-project.org/). Una vez descargado e instalado, debes instalar RStudio desde [aquí](https://www.rstudio.com/products/rstudio/download/#download). RStudio es una interfaz gráfica para R, y nos servirá para crear nuestros programas y el documento integrador.

- **Latex** servirá para redactar el documento en RStudio. Según seas usuario de Mac o Windows, debes descargarlo desde este [enlace](https://www.latex-project.org/get/). Para los que están usando **Windows**, se recomienda descargar **Miktex**. Al ejecutar el instalador básico recuerda instalar todos los paquetes faltantes, para ello selecciona la opción **yes** en esta ventana:


<center>
<img src="https://github.com/MAGALLANESJoseManuel/BITSS_ToolsWorkshop/raw/master/miktex0.png" style="width: 400px;"/>
</center>






- **Overleaf 2** sevirá para compartir el documento que salga de RStudio. es simplemente un editor en linea de Latex con varias propiedades interesantes para permitir que un externo lea tu trabajo. Puedes registrarte en este [enlace](https://www.overleaf.com/blog/641-try-out-overleaf-v2).

Instala todo esto en tu máquina, veremos cada una de ellas en este curso, sobre todo R, y además aprenderemos como hacerlas interactuar.

_____

## Intro a R

<br></br>

 

### Comandos básicos en R para exploración Univariada:

```{r, eval=FALSE}
# carga de datos
filename="indexes.csv"
dataidx=read.csv(filename, 
                 stringsAsFactors = T)

# ver primeras filas los datos:
head(dataidx)

```

Los datos ya llegaron 'limpios' desde Python.


Aquí podemos ver la distribución de una variable:
```{r, eval=FALSE}
demoTable=table(dataidx$Democracy)
demoTable
```

Ahora las frecuencias relativas:

```{r, eval=FALSE}
demoTableRel=round(prop.table(demoTable)*100,1)
demoTableRel
```

Y aquí el plot que representa esta distribución:

```{r, eval=FALSE}
title='Distribución de la Democracia'
paleta='red'
barplot(demoTableRel,main=title,
        col=paleta,ylim = c(0,100),
        ylab = "%")
```

Los mismo hacemos para ver la Libertad económica en el mundo en una tabla:
```{r, eval=FALSE}
ecoTable=table(dataidx$EconomicFreedom)
ecoTable
```

Sus  frecuencias relativas:
```{r, eval=FALSE}
ecoTableRel=round(prop.table(ecoTable)*100,1)
ecoTableRel
```

Y aquí el plot:
```{r, eval=FALSE}
title='Distribución de la Libertad Económica'
paleta='red'
barplot(ecoTableRel,main=title,
        col=paleta,ylim = c(0,100),
        ylab = "%")
```


La Libertad general en el mundo en una tabla:
```{r, eval=FALSE}
worldTable=table(dataidx$WorldFreedom)
worldTable
```

Ahora las frecuencias relativas:
```{r, eval=FALSE}
worldTableRel=round(prop.table(worldTable)*100,1)
worldTableRel
```


Y aquí el plot:
```{r, eval=FALSE}
title='Distribución de la Libertad en el Mundo'
paleta='red'
barplot(worldTableRel,main=title,
        col=paleta,ylim = c(0,100),
        ylab = "%")

```

La Libertad de prensa en el mundo en una tabla:
```{r, eval=FALSE}
pressTable=table(dataidx$PressFreedom)
pressTable

```

Sus frecuencias relativas:
```{r, eval=FALSE}
pressTableRel=round(prop.table(pressTable)*100,1)
pressTableRel
```

Y aquí el plot que representa esta distribución:
```{r, eval=FALSE}
title='Distribución de la Libertad de Prensa'
paleta='red'
barplot(pressTableRel,main=title,
        col=paleta,ylim = c(0,100),
        ylab = "%")
```


Podemos mostrar los estadísticos de cada variable:

```{r, eval=FALSE}
summary(dataidx[,-1])
```


### Comandos básicos en R para exploración Bivariada y modelamiento:


Si asumimos que estamos interesados en el impacto de los otros indices en el GDP, podemos primero ver la relación que tiene esta variable con todas las demás:
```{r, eval=FALSE}
explanans=names(dataidx)[c(3:6)]
corrDem=cor(x=dataidx[,2],
            y=dataidx[,explanans],
            use = "na.or.complete",
            method = "spearman")
corrDem

```

Veamos la correlación entre las variables independientes:

```{r, eval=FALSE}
corrTable=round(cor(dataidx[explanans],
               use = "na.or.complete"),2)

# ocultar media matriz
corrTable[upper.tri(corrTable)]<-""
as.data.frame(corrTable)

```


Finalmente, vemos los modelos propuestos. Primero sin la libertad mundial como independiente:
```{r, eval=FALSE}
LinRegA = lm(gdp ~ ., data = dataidx[,c(2:5)])
summary(LinRegA)

```


Luego con la libertad mundial

```{r, eval=FALSE}
LinRegB = lm(gdp ~ ., data = dataidx[,c(2:6)])
summary(LinRegB)
```


### Otros plots importantes

Podemos pintar un mapa con la información que tenemos. Veamos primero el mapa:
```{r, eval=FALSE}
library(rgdal)
folder='world_map'
file='world_map.shp'
mapaFile=file.path(folder,file)
mapaMundo = rgdal::readOGR(mapaFile,stringsAsFactors=F) 
plot(mapaMundo)
```

Para pintarlo, podemos crear conglomerados. Tenemos para ello que juntar añadir la información de los índices al mapa (no al revés). Veamos cuales son las claves:
```{r, eval=FALSE}
head(mapaMundo@data)
```

Usamos el campo respectivo para juntar los datos:

```{r, eval=FALSE}
# añadiendo información de indices al mapa:
mapaMundoAll=merge(mapaMundo,
                   dataidx, 
                   by.x='NAME', 
                   by.y='Country',all.x=F)
```

De ahí hagamos varios pasos:

```{r, eval=FALSE}
# nombres de las variables a utilizar
dimensions=names(dataidx)[c(3:6)]
```

```{r, eval=FALSE}
#creando subconjunto
dataCluster=mapaMundoAll@data[,c(dimensions)]
```


```{r, eval=FALSE}
# indicando que la data numerica es ordinal:
dataCluster=as.data.frame(lapply(dataCluster,as.ordered))
```

```{r, eval=FALSE}
# llamando librería:
library(cluster)

# creando matriz de distancias
dist=daisy(dataCluster,metric = "gower")

# aplicando algoritmo
pam_fit <- pam(dist, diss = TRUE, k = 3)

# añadiendo los clusters al mapa:
mapaMundoAll$cluster=pam_fit$clustering
```

Ya tenemos los clusters, pero hay que recordar que los números asignados no son necesariamente 'reveladores':
```{r, eval=FALSE}
aggregate(IndexofEconomicFreedom~cluster, 
          data=mapaMundoAll, 
          FUN=mean,
          na.rm=T)
```

Luego, debemos recodificar la columna cluster:

```{r, eval=FALSE}
library(car)
mapaMundoAll$cluster<-recode(mapaMundoAll$cluster,
                             "2=3;3=2")
```


Con los clusters calculados, podemos pintar el mundo:

```{r, eval=FALSE}
# que se pintara:
varToPlot=mapaMundoAll$cluster

#cuantos colores:
numberOfColors = length(unique(varToPlot)) 

#qué colores:
library(RColorBrewer)
colorForScale='Set2'
paleta = brewer.pal(numberOfColors, colorForScale)

# a dibujar:
plot(mapaMundo,col='grey',border=0)
plot(mapaMundoAll, col = paleta[varToPlot],border=F,add=T)
legend('left', legend = c("TOP","MEDIUM","LOW"), 
       fill = paleta,
       cex = 0.6, 
       bty = "n",
       title="Conglomerado")
```


_____

**AUSPICIO**: 

El desarrollo de estos contenidos ha sido posible gracias al grant del Berkeley Initiative for Transparency in the Social Sciences (BITSS) at the Center for Effective Global Action (CEGA) at the University of California, Berkeley


<center>
<img src="https://github.com/MAGALLANESJoseManuel/BITSS_ToolsWorkshop/raw/master/LogoBitss.jpg" style="width: 300px;"/>
</center>

**RECONOCIMIENTO**

EL Dr. Magallanes agradece a la Pontificia Universidad Católica del Perú, por su apoyo en la elaboración de este trabajo.

<center>
<img src="https://github.com/MAGALLANESJoseManuel/BITSS_ToolsWorkshop/raw/master/LogoPUCP.jpg" style="width: 200px;"/>
</center>


El autor reconoce el apoyo que el eScience Institute de la Universidad de Washington le ha brindado desde el 2015 para desarrollar su investigación en Ciencia de Datos.

<center>
<img src="https://github.com/MAGALLANESJoseManuel/BITSS_ToolsWorkshop/raw/master/LogoES.png" style="width: 300px;"/>
</center>

<br>
<br>








